{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does categorical labeling, returns a dictionary that shows the labels\n",
    "def cat_label(col_name, order_list):\n",
    "    cat_dtype = pd.api.types.CategoricalDtype(categories=order_list, ordered=True)\n",
    "    data[col_name] = data[col_name].astype(cat_dtype)\n",
    "    data[col_name+'_cat']=data[col_name].cat.codes\n",
    "    dictionary = dict(enumerate(data[col_name].cat.categories))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best C for PCA:', best_model_PCA.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11\n",
    "# encode Q11 part 1-7 all nan's to zero, and all texts to 1\n",
    "Q11_features = fill_info.nan_text('Q11', 1, 7)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q11_combined = combine_col.sum_int('Q11', 1, 7)\n",
    "# There are 904 missing responses for Q11\n",
    "how_many_nan(Q11_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13\n",
    "# encode Q13\n",
    "Q13_features = fill_info.nan_text('Q13', 1, 15)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q13_combined = combine_col.sum_int('Q13', 1, 15)\n",
    "# 1630 missing values\n",
    "how_many_nan(Q13_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14\n",
    "# encode Q14\n",
    "Q14_features = fill_info.nan_text('Q14', 1, 11)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q14_combined = combine_col.sum_int('Q14', 1, 11)\n",
    "# 1708 missing values\n",
    "how_many_nan(Q14_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q15\n",
    "Q15_features = fill_info.nan_text('Q15', 1, 7)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q15_combined = combine_col.sum_int('Q15', 1, 7)\n",
    "# 1772 missing values - question includes choice for people to select \"none\"\n",
    "how_many_nan(Q15_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q16\n",
    "Q16_features = fill_info.nan_text('Q16', 1, 18)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q16_combined = combine_col.sum_int('Q16', 1, 18)\n",
    "# 1798 missing values\n",
    "how_many_nan(Q16_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q19\n",
    "Q19_features = fill_info.nan_text('Q19', 1, 19)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q19_combined = combine_col.sum_int('Q19', 1, 19)\n",
    "# 1874 missing values\n",
    "how_many_nan(Q19_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q21\n",
    "Q21_features = fill_info.nan_text('Q21', 1, 13)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q21_combined = combine_col.sum_int('Q21', 1, 13)\n",
    "# 1935 missing values\n",
    "how_many_nan(Q21_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q27\n",
    "Q27_features = fill_info.nan_text('Q27', 1, 20)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q27_combined = combine_col.sum_int('Q27', 1, 20)\n",
    "# 6776 missing values\n",
    "how_many_nan(Q27_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q28\n",
    "Q28_features = fill_info.nan_text('Q28', 1, 43)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q28_combined = combine_col.sum_int('Q28', 1, 43)\n",
    "# 6900 missing values\n",
    "how_many_nan(Q28_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q29\n",
    "Q29_features = fill_info.nan_text('Q29', 1, 28)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q29_combined = combine_col.sum_int('Q29', 1, 28)\n",
    "# 7022 missing values\n",
    "how_many_nan(Q29_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q30\n",
    "Q30_features = fill_info.nan_text('Q30', 1, 25)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q30_combined = combine_col.sum_int('Q30', 1, 25)\n",
    "# 7764 missing values\n",
    "how_many_nan(Q30_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q31\n",
    "Q31_features = fill_info.nan_text('Q31', 1, 12)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q31_combined = combine_col.sum_int('Q31', 1, 12)\n",
    "# 3011 missing values\n",
    "how_many_nan(Q31_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q33\n",
    "Q33_features = fill_info.nan_text('Q33', 1, 11)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q33_combined = combine_col.sum_int('Q33', 1, 11)\n",
    "# 3085 missing values\n",
    "how_many_nan(Q33_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q36\n",
    "Q36_features = fill_info.nan_text('Q36', 1, 13)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q36_combined = combine_col.sum_int('Q36', 1, 13)\n",
    "# 3834 missing values\n",
    "how_many_nan(Q36_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q38\n",
    "Q38_features = fill_info.nan_text('Q38', 1, 22)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q38_combined = combine_col.sum_int('Q38', 1, 22)\n",
    "# 3459 missing values\n",
    "how_many_nan(Q38_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q42\n",
    "Q42_features = fill_info.nan_text('Q42', 1, 5)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q42_combined = combine_col.sum_int('Q42', 1, 5)\n",
    "# 5306 missing values\n",
    "how_many_nan(Q42_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q44\n",
    "Q44_features = fill_info.nan_text('Q44', 1, 6)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q44_combined = combine_col.sum_int('Q44', 1, 6)\n",
    "# 5469 missing values\n",
    "how_many_nan(Q44_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q45\n",
    "Q45_features = fill_info.nan_text('Q45', 1, 6)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q45_combined = combine_col.sum_int('Q45', 1, 6)\n",
    "# 5226 missing values\n",
    "how_many_nan(Q45_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q47\n",
    "Q47_features = fill_info.nan_text('Q47', 1, 16)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q47_combined = combine_col.sum_int('Q47', 1, 16)\n",
    "# 5382 missing values\n",
    "how_many_nan(Q47_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q49\n",
    "Q49_features = fill_info.nan_text('Q49', 1, 12)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q49_combined = combine_col.sum_int('Q49', 1, 12)\n",
    "# 5718 missing values\n",
    "how_many_nan(Q49_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Q50\n",
    "Q50_features = fill_info.nan_text('Q50', 1, 8)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q50_combined = combine_col.sum_int('Q50', 1, 8)\n",
    "# 5767 missing values\n",
    "how_many_nan(Q50_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combine_col:\n",
    "    # Function to concatenate multiple columns of texts in to one single column\n",
    "    def sum_int(col_name, start, end):\n",
    "        one = data[col_name+'_Part_'+str(start)]\n",
    "        two = data[col_name+'_Part_'+str(start+1)]\n",
    "        col_combined = one+two\n",
    "        # iterate from start to end\n",
    "        for i in range(start+2, end+1):\n",
    "            next_col = data[col_name+'_Part_'+str(i)]\n",
    "            col_combined = col_combined+next_col\n",
    "        # replace zero with NaN\n",
    "        col_combined = col_combined.replace(0, np.nan)\n",
    "        return col_combined\n",
    "    # Function to concatenate multiple columns of texts in to one single column\n",
    "    def join_text(col_name, start, end):\n",
    "        one = data[col_name+'_Part_'+str(start)]\n",
    "        two = data[col_name+'_Part_'+str(start+1)]\n",
    "        col_combined = one.astype(str)+' '+two\n",
    "        # iterate from start to end\n",
    "        for i in range(start+2, end+1):\n",
    "            next_col = data[col_name+'_Part_'+str(i)]\n",
    "            col_combined = col_combined.astype(str)+' '+next_col\n",
    "        # Replace empty cells with NaN\n",
    "        col_combined = col_combined.str.strip() # remove leading/trailing space in a column\n",
    "        col_combined = col_combined.replace(r'^\\s*$', regex=True).replace('',np.nan)\n",
    "        return col_combined\n",
    "# Class for filling in information\n",
    "class fill_info:\n",
    "    # Function to fill NaN values in multiple columns with 0\n",
    "    def nan2zero(col_name, start, end):\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "    # Function to fill all text values with 1b\n",
    "    def text2one(col_name, start, end):\n",
    "        # Before converting all texts to 1, save a list of the categories\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1): #text2one\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(bool).astype(int)\n",
    "        return features_list\n",
    "    # Function to fill NaN values in multiple columns with space\n",
    "    def nan2space(col_name, start, end):\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(' ')\n",
    "    # Combination\n",
    "    def nan_text(col_name,start, end):\n",
    "        for i in range (start, end+1): #nan2zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        # Before converting all texts to 1, save a list of the categories\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1): # save features to a list\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        for i in range (start, end+1): #text2one\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(bool).astype(int)\n",
    "        return features_list\n",
    "    # Function for getting the features of every column before they are converted to numbers\n",
    "    def get_features(col_name, start, end):\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1):\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        return features_list\n",
    "    def col2int(col_name, start, end):\n",
    "        for i in range (start, end+1): #fill nan with zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        for i in range (start, end+1): # convert everything to type float\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(float)\n",
    "# encode columns\n",
    "def encode_col(col_name, start, end):\n",
    "    features = fill_info.nan_text(col_name, start, end)\n",
    "    combined = combine_col.sum_int(col_name, start, end)\n",
    "    return features, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepts a column name and a list of words that needs to be removed\n",
    "def remove_words(col_name, unwanted_words):\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(unwanted_words))\n",
    "    data[col_name] = data[col_name].str.replace(pat, '')\n",
    "    data[col_name] = data[col_name].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate how many missing values are in a column\n",
    "# def how_many_nan(col_name):\n",
    "#     amount = col_name[col_name.isna()].shape[0]\n",
    "#     return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "kfold = KFold(n_splits=10)\n",
    "kfold.get_n_splits(X)\n",
    "\n",
    "best_model_FS = model\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "\n",
    "# Use the selected features\n",
    "X_proc = X_train_proc\n",
    "C_list = [0.001,0.01,0.05,0.1,0.5,1,5,10, 100]\n",
    "solver_list = ['newton-cg','lbfgs','liblinear','sag']\n",
    "\n",
    "for C in C_list:\n",
    "    for solver in solver_list:\n",
    "        # show progress percentage\n",
    "        current_c = C_list.index(C)+1\n",
    "        progress = (current_c/len(C_list))*100\n",
    "        clear_output(wait=True)\n",
    "        print('Progress: ' + str(round(progress, 2)) +' %. Solver: ' + solver)\n",
    "\n",
    "        model = LogisticRegression(C=C, solver=solver)\n",
    "        accuracy = np.zeros(10)\n",
    "        np_idx = 0\n",
    "\n",
    "        for train_idx, test_idx in kfold.split(X_proc):\n",
    "            X_train_tune, X_test_tune = X_proc.values[train_idx], X_proc.values[test_idx]\n",
    "            y_train_tune, y_test_tune = y_train.values[train_idx], y_train.values[test_idx]\n",
    "\n",
    "            X_train_tune = scaler.fit_transform(X_train_tune)\n",
    "            X_test_tune = scaler.transform(X_test_tune)\n",
    "\n",
    "            model.fit(X_train_tune, y_train_tune)\n",
    "            predictions = model.predict(X_test_tune)\n",
    "\n",
    "            ACC = model.score(X_test_tune,y_test_tune)\n",
    "\n",
    "            accuracy[np_idx] = ACC*100\n",
    "            np_idx += 1\n",
    "\n",
    "        if np.mean(accuracy) > best_accuracy:\n",
    "            best_model_FS = model\n",
    "            best_params = {'C':C, 'solver':solver}\n",
    "            best_accuracy = np.mean(accuracy)\n",
    "            best_std = np.std(accuracy)\n",
    "\n",
    "print (best_params)\n",
    "print (\"Best Score: {}%({}%)\".format(round(best_accuracy,3),round(best_std,3)))      \n",
    "print (\"\\nThe optimal log model uses C={}, and a {} solver, and has a cross validation score of {}% with a standard deviation of {}%\".format(best_params['C'],best_params['solver'],round(best_accuracy,3),round(best_std,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "kfold = KFold(n_splits=10)\n",
    "kfold.get_n_splits(X)\n",
    "\n",
    "best_model_PCA = model\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "\n",
    "# Use the selected features\n",
    "X_proc = X_train_pca\n",
    "C_list = [0.001,0.01,0.05,0.1,0.5,1,5,10, 100]\n",
    "solver_list = ['newton-cg','lbfgs','liblinear','sag']\n",
    "\n",
    "for C in C_list:\n",
    "    for solver in solver_list:\n",
    "        # show progress percentage\n",
    "        current_c = C_list.index(C)+1\n",
    "        progress = (current_c/len(C_list))*100\n",
    "        clear_output(wait=True)\n",
    "        print('Progress: ' + str(round(progress, 2)) +' %. Solver: ' + solver)\n",
    "\n",
    "        model = LogisticRegression(C=C, solver=solver)\n",
    "        accuracy = np.zeros(10)\n",
    "        np_idx = 0\n",
    "\n",
    "        for train_idx, test_idx in kfold.split(X_proc):\n",
    "            X_train_tune, X_test_tune = X_proc.values[train_idx], X_proc.values[test_idx]\n",
    "            y_train_tune, y_test_tune = y_train.values[train_idx], y_train.values[test_idx]\n",
    "\n",
    "            X_train_tune = scaler.fit_transform(X_train_tune)\n",
    "            X_test_tune = scaler.transform(X_test_tune)\n",
    "\n",
    "            model.fit(X_train_tune, y_train_tune)\n",
    "            predictions = model.predict(X_test_tune)\n",
    "\n",
    "            ACC = model.score(X_test_tune,y_test_tune)\n",
    "\n",
    "            accuracy[np_idx] = ACC*100\n",
    "            np_idx += 1\n",
    "\n",
    "        if np.mean(accuracy) > best_accuracy:\n",
    "            best_model_PCA = model\n",
    "            best_params = {'C':C, 'solver':solver}\n",
    "            best_accuracy = np.mean(accuracy)\n",
    "            best_std = np.std(accuracy)\n",
    "\n",
    "print (best_params)\n",
    "print (\"Best Score: {}%({}%)\".format(round(best_accuracy,3),round(best_std,3)))      \n",
    "print (\"\\nThe optimal log model uses C={}, and a {} solver, and has a cross validation score of {}% with a standard deviation of {}%\".format(best_params['C'],best_params['solver'],round(best_accuracy,3),round(best_std,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model and define the hyperparameters\n",
    "model = LogisticRegression()\n",
    "C_list = [0.001,0.01,0.05,0.1,0.5,1,5]\n",
    "scores = ['accuracy']\n",
    "hyperparameters = dict(C=C_list)\n",
    "\n",
    "# perform grid search to tune the model with random forest selected features\n",
    "FS_model = GridSearchCV(model, hyperparameters, cv=10, scoring=scores, n_jobs = -1, refit=False,  verbose=1)\n",
    "best_model_FS = FS_model.fit(X_train_proc, y_train)\n",
    "\n",
    "# perform grid search to tune the model with random forest selected features\n",
    "PCA_model = GridSearchCV(model, hyperparameters, cv=10, scoring=scores, n_jobs = -1, refit=False,  verbose=1)\n",
    "best_model_PCA = PCA_model.fit(X_train_pca, y_train)\n",
    "\n",
    "a = best_model_FS.cv_results_['rank_test_accuracy']\n",
    "index, = np.where(a==1)\n",
    "print('Best C for FS:', C_list[index[0]])\n",
    "a = best_model_PCA.cv_results_['rank_test_accuracy']\n",
    "index, = np.where(a==1)\n",
    "print('Best C for PCA:', C_list[index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function that does categorical labeling, returns a dictionary that shows the labels\n",
    "# def cat_label(col_name, order_list):\n",
    "#     data[col_name]=data[col_name].astype('category', categories=order_list, ordered=True)\n",
    "#     data[col_name+'_cat']=data[col_name].cat.codes\n",
    "#     dictionary = dict(enumerate(data[col_name].cat.categories))\n",
    "#     return dictionary\n",
    "# Pandas 0.25.2 (IBM Cognitive Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_test2 = y_test\n",
    "y_test2 = y_test2.reset_index()\n",
    "y_test2.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "# convert predictions from array to series, then to an ordered dataframe\n",
    "y_test_count = y_test2.Q9_cat.value_counts()\n",
    "_dict = y_test_count.to_dict()\n",
    "ordered = collections.OrderedDict(sorted(_dict.items()))\n",
    "y_test_df = pd.DataFrame.from_dict(ordered, orient='index')\n",
    "y_test_df.columns = ['y_test']\n",
    "# convert predictions from array to series, then to an ordered dataframe\n",
    "FS_predictions_series = pd.Series(FS_predictions)\n",
    "FS_pred_count = FS_predictions_series.value_counts()\n",
    "_dict = FS_pred_count.to_dict()\n",
    "ordered = collections.OrderedDict(sorted(_dict.items()))\n",
    "FS_pred_df = pd.DataFrame.from_dict(ordered, orient='index')\n",
    "FS_pred_df.columns = ['FS']\n",
    "\n",
    "y_test_df.plot(y='y_test', kind='bar', use_index=True)\n",
    "plt.title(\"Salary Label Distribution\")\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Salary')\n",
    "\n",
    "FS_pred_df.plot(y='FS', kind='bar', use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions from array to series, then to an ordered dataframe\n",
    "y_test_count = y_test2.Q9_cat.value_counts()\n",
    "_dict = y_test_count.to_dict()\n",
    "ordered = collections.OrderedDict(sorted(_dict.items()))\n",
    "y_test_df = pd.DataFrame.from_dict(ordered, orient='index')\n",
    "y_test_df.columns = ['y_test']\n",
    "# convert predictions from array to series, then to an ordered dataframe\n",
    "FS_predictions_series = pd.Series(FS_predictions)\n",
    "FS_pred_count = FS_predictions_series.value_counts()\n",
    "_dict = FS_pred_count.to_dict()\n",
    "ordered = collections.OrderedDict(sorted(_dict.items()))\n",
    "FS_pred_df = pd.DataFrame.from_dict(ordered, orient='index')\n",
    "FS_pred_df.columns = ['FS']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
