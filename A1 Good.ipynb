{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "# The following line is needed to show plots inline in notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Kaggle_Salary.csv')\n",
    "# drop row index 0 because it holds the Questions (inplace is to remove permanently)\n",
    "data.drop(data.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate how many missing values are in a column\n",
    "def how_many_nan(col_name):\n",
    "    amount = col_name[col_name.isna()].shape[0]\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert salary in to categorical data\n",
    "data.Q9 = pd.Categorical(data.Q9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Gender\n",
    "# Combine gender cateogires less than 150 with Other\n",
    "gender_count = data.Q1.value_counts()\n",
    "value_mask = data.Q1.isin(gender_count.index[gender_count < 150]) \n",
    "data.loc[value_mask,'Q1'] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Age\n",
    "age_count = data.Q2.value_counts()\n",
    "value_mask = data.Q2.isin(age_count.index[age_count < 180]) \n",
    "data.loc[value_mask,'Q2'] = \"70+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Countries\n",
    "# Categorize any country less than a threshold count in to other\n",
    "countries_count = data.Q3.value_counts()\n",
    "value_mask = data.Q3.isin(countries_count.index[countries_count < 100]) \n",
    "data.loc[value_mask,'Q3'] = \"Other\"\n",
    "# Simplify Name\n",
    "data['Q3'] = data['Q3'].replace('United States of America', 'USA')\n",
    "data['Q3'] = data['Q3'].replace('United Kingdom of Great Britain and Northern Ireland', 'UKGBNI')\n",
    "data['Q3'] = data['Q3'].replace('I do not wish to disclose my location', 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Highest level of education\n",
    "degree_count = data.Q4.value_counts(normalize=True)\n",
    "# Simplify category name\n",
    "data['Q4'] = data['Q4'].replace('Some college/university study without earning a bachelorâ€™s degree', 'Non-conferred')\n",
    "data['Q4'] = data['Q4'].replace('No formal education past high school', 'Secondary School')\n",
    "# sns.catplot(x='Q4', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(20,10)\n",
    "# Since \"Non-conferred\" and \"I prefer not to answer\" show similar salary earnings, I can combine them\n",
    "data['Q4'] = data['Q4'].replace('Non-conferred', 'Other')\n",
    "data['Q4'] = data['Q4'].replace('I prefer not to answer', 'Other')\n",
    "# sns.catplot(x='Q4', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Major in University/College\n",
    "# There is 135 missing values\n",
    "a = data[data['Q5'].isna()]\n",
    "how_many_nan(data['Q5'])\n",
    "# Simplified naming\n",
    "data['Q5'] = data['Q5'].replace('A business discipline (accounting, economics, finance, etc.)', 'Business')\n",
    "data['Q5'] = data['Q5'].replace('Information technology, networking, or system administration', 'Information technology')\n",
    "data['Q5'] = data['Q5'].replace('Medical or life sciences (biology, chemistry, medicine, etc.)', 'Medical/Life Science')\n",
    "data['Q5'] = data['Q5'].replace('Social sciences (anthropology, psychology, sociology, etc.)', 'Social Science')\n",
    "data['Q5'] = data['Q5'].replace('Humanities (history, literature, philosophy, etc.)', 'Humanities')\n",
    "# Grouped together non-STEM with others\n",
    "data['Q5'] = data['Q5'].replace('I never declared a major', 'Other')\n",
    "data['Q5'] = data['Q5'].replace('Fine arts or performing arts', 'Other')\n",
    "data['Q5'] = data['Q5'].replace('Humanities', 'Other')\n",
    "# sns.catplot(x='Q5', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(60,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Position Title\n",
    "# Eliminate position titles less than a threshold\n",
    "title_count = data.Q6.value_counts()\n",
    "value_mask = data.Q6.isin(title_count.index[title_count < 100]) \n",
    "data.loc[value_mask,'Q6'] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computers/Technology                      0.270854\n",
       "I am a student                            0.145700\n",
       "Academics/Education                       0.128395\n",
       "Accounting/Finance                        0.076544\n",
       "Other                                     0.048610\n",
       "Online Service/Internet-based Services    0.046341\n",
       "Medical/Pharmaceutical                    0.038369\n",
       "Government/Public Service                 0.033962\n",
       "Insurance/Risk Assessment                 0.029425\n",
       "Manufacturing/Fabrication                 0.028194\n",
       "Marketing/CRM                             0.025018\n",
       "Retail/Sales                              0.023073\n",
       "Energy/Mining                             0.022360\n",
       "Broadcasting/Communications               0.020675\n",
       "Online Business/Internet-based Sales      0.017629\n",
       "Shipping/Transportation                   0.015361\n",
       "Non-profit/Service                        0.009916\n",
       "Hospitality/Entertainment/Sports          0.009852\n",
       "Military/Security/Defense                 0.009722\n",
       "Name: Q7, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7: Industry\n",
    "industry_count = data.Q7.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-3      0.564710\n",
       "3-5      0.159773\n",
       "5-10     0.128509\n",
       "10-15    0.073145\n",
       "15-20    0.038755\n",
       "20-30    0.025728\n",
       "30 +     0.009379\n",
       "Name: Q8, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8: Years of Experience\n",
    "# There's 76 missing values - Should just remove it\n",
    "how_many_nan(data['Q8'])\n",
    "# Recategorize YOE\n",
    "data['Q8'] = data['Q8'].replace('0-1', '0-3') # 0-3 years\n",
    "data['Q8'] = data['Q8'].replace('1-2', '0-3')\n",
    "data['Q8'] = data['Q8'].replace('2-3', '0-3')\n",
    "data['Q8'] = data['Q8'].replace('3-4', '3-5') # 3-5 years\n",
    "data['Q8'] = data['Q8'].replace('4-5', '3-5')\n",
    "data['Q8'] = data['Q8'].replace('20-25', '20-30') # 20-30 years\n",
    "data['Q8'] = data['Q8'].replace('25-30', '20-30')\n",
    "data.Q8.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10: Does current employer incorporate ML into their business\n",
    "# There's 292 missing values\n",
    "how_many_nan(data['Q10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(col_name, unwanted_words):\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(unwanted_words))\n",
    "    data[col_name] = data[col_name].str.replace(pat, '')\n",
    "    data[col_name] = data[col_name].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Q40\n",
    "Q40_words = ['Independent', 'projects', 'are', 'important', 'than', 'academic', 'achievements']\n",
    "remove_words('Q40', Q40_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combine_col:\n",
    "    # Function to concatenate multiple columns of texts in to one single column\n",
    "    def sum_int(col_name, start, end):\n",
    "        one = data[col_name+'_Part_'+str(start)]\n",
    "        two = data[col_name+'_Part_'+str(start+1)]\n",
    "        col_combined = one+two\n",
    "        # iterate from start to end\n",
    "        for i in range(start+2, end+1):\n",
    "            next_col = data[col_name+'_Part_'+str(i)]\n",
    "            col_combined = col_combined+next_col\n",
    "        # replace zero with NaN\n",
    "        col_combined = col_combined.replace(0, np.nan)\n",
    "        return col_combined\n",
    "    # Function to concatenate multiple columns of texts in to one single column\n",
    "    def join_text(col_name, start, end):\n",
    "        one = data[col_name+'_Part_'+str(start)]\n",
    "        two = data[col_name+'_Part_'+str(start+1)]\n",
    "        col_combined = one.astype(str)+' '+two\n",
    "        # iterate from start to end\n",
    "        for i in range(start+2, end+1):\n",
    "            next_col = data[col_name+'_Part_'+str(i)]\n",
    "            col_combined = col_combined.astype(str)+' '+next_col\n",
    "        # Replace empty cells with NaN\n",
    "        col_combined = col_combined.str.strip() # remove leading/trailing space in a column\n",
    "        col_combined = col_combined.replace(r'^\\s*$', regex=True).replace('',np.nan)\n",
    "        return col_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for filling in information\n",
    "class fill_info:\n",
    "    # Function to fill NaN values in multiple columns with 0\n",
    "    def nan2zero(col_name, start, end):\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "    # Function to fill all text values with 1b\n",
    "    def text2one(col_name, start, end):\n",
    "        # Before converting all texts to 1, save a list of the categories\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1): #text2one\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(bool).astype(int)\n",
    "        return features_list\n",
    "    # Function to fill NaN values in multiple columns with space\n",
    "    def nan2space(col_name, start, end):\n",
    "        for i in range (start, end+1):\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(' ')\n",
    "    # Combination\n",
    "    def nan_text(col_name,start, end):\n",
    "        for i in range (start, end+1): #nan2zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        # Before converting all texts to 1, save a list of the categories\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1): #text2one\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        for i in range (start, end+1): #text2one\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(bool).astype(int)\n",
    "        return features_list\n",
    "    # Function for getting the features of every column before they are converted to numbers\n",
    "    def get_features(col_name, start, end):\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1):\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        return features_list\n",
    "    def col2int(col_name, start, end):\n",
    "        for i in range (start, end+1): #fill nan with zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        for i in range (start, end+1): # convert everything to type float\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(float)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(col_name):\n",
    "    global data\n",
    "    dummy = pd.get_dummies(data[col_name], prefix=col_name)\n",
    "    data = data.drop([col_name], axis=1)\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_dummies = dummy('Q1')\n",
    "Q2_dummies = dummy('Q2')\n",
    "Q3_dummies = dummy('Q3')\n",
    "Q4_dummies = dummy('Q4')\n",
    "Q5_dummies = dummy('Q5')\n",
    "Q6_dummies = dummy('Q6')\n",
    "Q7_dummies = dummy('Q7')\n",
    "Q8_dummies = dummy('Q8')\n",
    "Q10_dummies = dummy('Q10')\n",
    "Q12_dummies = dummy('Q12_MULTIPLE_CHOICE')\n",
    "Q17_dummies = dummy('Q17')\n",
    "Q18_dummies = dummy('Q18')\n",
    "Q20_dummies = dummy('Q20')\n",
    "Q22_dummies = dummy('Q22')\n",
    "Q23_dummies = dummy('Q23')\n",
    "Q24_dummies = dummy('Q24')\n",
    "Q25_dummies = dummy('Q25')\n",
    "Q26_dummies = dummy('Q26')\n",
    "Q32_dummies = dummy('Q32')\n",
    "Q37_dummies = dummy('Q37')\n",
    "Q39P1_dummies = dummy('Q39_Part_1')\n",
    "Q39P2_dummies = dummy('Q39_Part_2')\n",
    "Q40_dummies = dummy('Q40')\n",
    "Q41P1_dummies = dummy('Q41_Part_1')\n",
    "Q41P2_dummies = dummy('Q41_Part_2')\n",
    "Q41P3_dummies = dummy('Q41_Part_3')\n",
    "Q43_dummies = dummy('Q43')\n",
    "Q46_dummies = dummy('Q46')\n",
    "Q48_dummies = dummy('Q48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q34\n",
    "fill_info.col2int('Q34', 1, 6)\n",
    "# Q35\n",
    "fill_info.col2int('Q35', 1, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q11\n",
    "# encode Q11 part 1-7 all nan's to zero, and all texts to 1\n",
    "Q11_features = fill_info.nan_text('Q11', 1, 7)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q11_combined = combine_col.sum_int('Q11', 1, 7)\n",
    "# There are 904 missing responses for Q11\n",
    "how_many_nan(Q11_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1630"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q13\n",
    "# encode Q13\n",
    "Q13_features = fill_info.nan_text('Q13', 1, 15)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q13_combined = combine_col.sum_int('Q13', 1, 15)\n",
    "# 1630 missing values\n",
    "how_many_nan(Q13_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q14\n",
    "# encode Q14\n",
    "Q14_features = fill_info.nan_text('Q14', 1, 11)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q14_combined = combine_col.sum_int('Q14', 1, 11)\n",
    "# 1708 missing values\n",
    "how_many_nan(Q14_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1772"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q15\n",
    "Q15_features = fill_info.nan_text('Q15', 1, 7)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q15_combined = combine_col.sum_int('Q15', 1, 7)\n",
    "# 1772 missing values - question includes choice for people to select \"none\"\n",
    "how_many_nan(Q15_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1798"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q16\n",
    "Q16_features = fill_info.nan_text('Q16', 1, 18)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q16_combined = combine_col.sum_int('Q16', 1, 18)\n",
    "# 1798 missing values\n",
    "how_many_nan(Q16_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q19\n",
    "Q19_features = fill_info.nan_text('Q19', 1, 19)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q19_combined = combine_col.sum_int('Q19', 1, 19)\n",
    "# 1874 missing values\n",
    "how_many_nan(Q19_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q21\n",
    "Q21_features = fill_info.nan_text('Q21', 1, 13)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q21_combined = combine_col.sum_int('Q21', 1, 13)\n",
    "# 1935 missing values\n",
    "how_many_nan(Q21_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6776"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q27\n",
    "Q27_features = fill_info.nan_text('Q27', 1, 20)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q27_combined = combine_col.sum_int('Q27', 1, 20)\n",
    "# 6776 missing values\n",
    "how_many_nan(Q27_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6900"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q28\n",
    "Q28_features = fill_info.nan_text('Q28', 1, 43)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q28_combined = combine_col.sum_int('Q28', 1, 43)\n",
    "# 6900 missing values\n",
    "how_many_nan(Q28_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7022"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q29\n",
    "Q29_features = fill_info.nan_text('Q29', 1, 28)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q29_combined = combine_col.sum_int('Q29', 1, 28)\n",
    "# 7022 missing values\n",
    "how_many_nan(Q29_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7764"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q30\n",
    "Q30_features = fill_info.nan_text('Q30', 1, 25)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q30_combined = combine_col.sum_int('Q30', 1, 25)\n",
    "# 7764 missing values\n",
    "how_many_nan(Q30_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3011"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q31\n",
    "Q31_features = fill_info.nan_text('Q31', 1, 12)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q31_combined = combine_col.sum_int('Q31', 1, 12)\n",
    "# 3011 missing values\n",
    "how_many_nan(Q31_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3085"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q33\n",
    "Q33_features = fill_info.nan_text('Q33', 1, 11)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q33_combined = combine_col.sum_int('Q33', 1, 11)\n",
    "# 3085 missing values\n",
    "how_many_nan(Q33_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3834"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q36\n",
    "Q36_features = fill_info.nan_text('Q36', 1, 13)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q36_combined = combine_col.sum_int('Q36', 1, 13)\n",
    "# 3834 missing values\n",
    "how_many_nan(Q36_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3459"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q38\n",
    "Q38_features = fill_info.nan_text('Q38', 1, 22)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q38_combined = combine_col.sum_int('Q38', 1, 22)\n",
    "# 3459 missing values\n",
    "how_many_nan(Q38_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5306"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q42\n",
    "Q42_features = fill_info.nan_text('Q42', 1, 5)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q42_combined = combine_col.sum_int('Q42', 1, 5)\n",
    "# 5306 missing values\n",
    "how_many_nan(Q42_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5469"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q44\n",
    "Q44_features = fill_info.nan_text('Q44', 1, 6)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q44_combined = combine_col.sum_int('Q44', 1, 6)\n",
    "# 5469 missing values\n",
    "how_many_nan(Q44_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5226"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q45\n",
    "Q45_features = fill_info.nan_text('Q45', 1, 6)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q45_combined = combine_col.sum_int('Q45', 1, 6)\n",
    "# 5226 missing values\n",
    "how_many_nan(Q45_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q47\n",
    "Q47_features = fill_info.nan_text('Q47', 1, 16)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q47_combined = combine_col.sum_int('Q47', 1, 16)\n",
    "# 5382 missing values\n",
    "how_many_nan(Q47_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5718"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q49\n",
    "Q49_features = fill_info.nan_text('Q49', 1, 12)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q49_combined = combine_col.sum_int('Q49', 1, 12)\n",
    "# 5718 missing values\n",
    "how_many_nan(Q49_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5767"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Q50\n",
    "Q50_features = fill_info.nan_text('Q50', 1, 8)\n",
    "# Combine columns of int (0 or 1) into a single column of sum (int)\n",
    "Q50_combined = combine_col.sum_int('Q50', 1, 8)\n",
    "# 5767 missing values\n",
    "how_many_nan(Q50_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dummy data\n",
    "dummy_data = pd.concat([Q1_dummies, Q2_dummies, Q3_dummies, Q4_dummies, Q5_dummies, Q6_dummies, Q7_dummies, Q8_dummies, Q10_dummies, Q12_dummies, Q17_dummies, Q18_dummies, Q20_dummies, Q22_dummies, Q23_dummies, Q24_dummies, Q25_dummies, Q26_dummies, Q32_dummies, Q37_dummies, Q39P1_dummies, Q39P2_dummies, Q40_dummies, Q41P1_dummies, Q41P2_dummies, Q41P3_dummies, Q43_dummies, Q46_dummies, Q48_dummies], axis=1)\n",
    "# drop any column with \"TEXT\" in title\n",
    "data.drop([col for col in data.columns if 'TEXT' in col],axis=1,inplace=True)\n",
    "# drop other unecessary columns\n",
    "data.drop(['Unnamed: 0', 'Time from Start to Finish (seconds)', 'index'], axis=1, inplace=True)\n",
    "# form cleaned data\n",
    "cleaned_data = pd.concat([dummy_data, data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data.drop(['Q9'],axis=1)\n",
    "y = cleaned_data['Q9']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = LogisticRegression()    \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy: 0.784%\n",
      "Fold 2: Accuracy: 0.73%\n",
      "Fold 3: Accuracy: 0.711%\n",
      "Fold 4: Accuracy: 0.747%\n",
      "Fold 5: Accuracy: 0.75%\n",
      "Fold 6: Accuracy: 0.746%\n",
      "Fold 7: Accuracy: 0.771%\n",
      "Fold 8: Accuracy: 0.767%\n",
      "Fold 9: Accuracy: 0.737%\n",
      "Fold 10: Accuracy: 0.772%\n",
      "Average Score: 75.161%(2.114%)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "kfold = KFold(n_splits=10)\n",
    "kfold.get_n_splits(X)\n",
    "\n",
    "accuracy = np.zeros(10)\n",
    "np_idx = 0\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.values[train_idx], X.values[test_idx]\n",
    "    y_train, y_test = y.values[train_idx], y.values[test_idx]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    TN = confusion_matrix(y_test, predictions)[0][0]\n",
    "    FP = confusion_matrix(y_test, predictions)[0][1]\n",
    "    FN = confusion_matrix(y_test, predictions)[1][0]\n",
    "    TP = confusion_matrix(y_test, predictions)[1][1]\n",
    "    total = TN + FP + FN + TP\n",
    "    ACC = (TP + TN) / float(total)\n",
    "    \n",
    "    accuracy[np_idx] = ACC*100\n",
    "    np_idx += 1\n",
    "    \n",
    "    print (\"Fold {}: Accuracy: {}%\".format(np_idx, round(ACC,3)))   \n",
    "\n",
    "print (\"Average Score: {}%({}%)\".format(round(np.mean(accuracy),3),round(np.std(accuracy),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
