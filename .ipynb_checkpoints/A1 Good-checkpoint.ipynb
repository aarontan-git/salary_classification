{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "# The following line is needed to show plots inline in notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Kaggle_Salary.csv')\n",
    "# drop row index 0 because it holds the Questions (inplace is to remove permanently)\n",
    "data.drop(data.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate how many missing values are in a column\n",
    "def how_many_nan(col_name):\n",
    "    amount = col_name[col_name.isna()].shape[0]\n",
    "    return amount\n",
    "# accepts a column name and a list of words that needs to be removed\n",
    "def remove_words(col_name, unwanted_words):\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(unwanted_words))\n",
    "    data[col_name] = data[col_name].str.replace(pat, '')\n",
    "    data[col_name] = data[col_name].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert salary in to categorical data\n",
    "# data.Q9 = pd.Categorical(data.Q9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the salary range for data exploration\n",
    "def encode_salary(salary):\n",
    "    if \"0-10,000\" in salary:\n",
    "        return 5000\n",
    "    if \"10-20,000\" in salary:\n",
    "        return 15000\n",
    "    if \"20-30,000\" in salary:\n",
    "        return 25000\n",
    "    if \"30-40,000\" in salary:\n",
    "        return 35000\n",
    "    if \"40-50,000\" in salary:\n",
    "        return 45000\n",
    "    if \"50-60,000\" in salary:\n",
    "        return 55000\n",
    "    if \"60-70,000\" in salary:\n",
    "        return 65000\n",
    "    if \"70-80,000\" in salary:\n",
    "        return 75000\n",
    "    if \"80-90,000\" in salary:\n",
    "        return 85000\n",
    "    if \"90-100,000\" in salary:\n",
    "        return 95000\n",
    "    if \"100-125,000\" in salary:\n",
    "        return 112500\n",
    "    if \"125-150,000\" in salary:\n",
    "        return 137500\n",
    "    if \"150-200,000\" in salary:\n",
    "        return 175000\n",
    "    if \"200-250,000\" in salary:\n",
    "        return 225000\n",
    "    if \"250-300,000\" in salary:\n",
    "        return 275000\n",
    "    if \"300-400,000\" in salary:\n",
    "        return 250000\n",
    "    if \"400-500,000\" in salary:\n",
    "        return 450000\n",
    "    if \"500,000+\" in salary:\n",
    "        return 550000\n",
    "# Create a new column with the encoded salary\n",
    "data[\"Salary_label\"]=data[\"Q9\"].apply(encode_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Gender\n",
    "# Combine gender cateogires less than 150 with Other (prefer not to say, prefer to self-describe)\n",
    "gender_count = data.Q1.value_counts()\n",
    "value_mask = data.Q1.isin(gender_count.index[gender_count < 150]) \n",
    "data.loc[value_mask,'Q1'] = \"Other\"\n",
    "# sns.catplot(x='Q1', y='Salary_label', data=data, order=['Female','Male','Other'], kind=\"box\").fig.set_size_inches(10,5)\n",
    "# plt.ylim(0, 250000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Age\n",
    "age_count = data.Q2.value_counts()\n",
    "# Made a new age category of above 70 years old\n",
    "value_mask = data.Q2.isin(age_count.index[age_count < 180]) \n",
    "data.loc[value_mask,'Q2'] = \"70+\"\n",
    "# sns.catplot(x='Q2', y='Salary_label', data=data, order = ['18-21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-69','70+'], kind=\"box\").fig.set_size_inches(10,5)\n",
    "# plt.ylim(0, 300000) # limit the y axis to 300000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Countries\n",
    "# Categorize any country less than a threshold count in to other\n",
    "countries_count = data.Q3.value_counts()\n",
    "value_mask = data.Q3.isin(countries_count.index[countries_count < 200]) \n",
    "data.loc[value_mask,'Q3'] = \"Other\"\n",
    "# Simplify Name\n",
    "data['Q3'] = data['Q3'].replace('United States of America', 'USA')\n",
    "data['Q3'] = data['Q3'].replace('United Kingdom of Great Britain and Northern Ireland', 'UKGBNI')\n",
    "# Group together \"I do not wish to disclose my location\" with \"Other\"\n",
    "data['Q3'] = data['Q3'].replace('I do not wish to disclose my location', 'Other')\n",
    "# sns.catplot(x='Q3', y='Salary_label', data=data, order = ['India','China','Russia','Brazil','Poland','Other','Italy','Spain','France','Germany','Japan','UKGBNI','Canada','Australia','USA'],kind=\"box\").fig.set_size_inches(20,8)\n",
    "# plt.ylim(0, 300000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Highest level of education "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Highest level of education\n",
    "degree_count = data.Q4.value_counts(normalize=True)\n",
    "# Simplify category name\n",
    "data['Q4'] = data['Q4'].replace('Some college/university study without earning a bachelor’s degree', 'Non-conferred')\n",
    "data['Q4'] = data['Q4'].replace('No formal education past high school', 'Secondary School')\n",
    "# sns.catplot(x='Q4', y='Salary_label', data=data, order=['I prefer not to answer','Secondary School','Professional degree','Non-conferred','Bachelor’s degree','Master’s degree','Doctoral degree'],kind=\"box\").fig.set_size_inches(20,10)\n",
    "# plt.ylim(0, 200000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since \"Non-conferred\" and \"I prefer not to answer\" show similar salary earnings, I can combine them\n",
    "data['Q4'] = data['Q4'].replace('Non-conferred', 'Other')\n",
    "data['Q4'] = data['Q4'].replace('I prefer not to answer', 'Other')\n",
    "data['Q4'] = data['Q4'].replace('Bachelor’s degree', 'Other')\n",
    "# sns.catplot(x='Q4', y='Salary_label', data=data, order=['Other','Secondary School','Professional degree','Master’s degree','Doctoral degree'],kind=\"box\").fig.set_size_inches(20,10)\n",
    "# plt.ylim(0, 200000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Major in University/College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Major in University/College\n",
    "# There is 135 missing values\n",
    "a = data[data['Q5'].isna()]\n",
    "how_many_nan(data['Q5'])\n",
    "# Simplified naming\n",
    "data['Q5'] = data['Q5'].replace('A business discipline (accounting, economics, finance, etc.)', 'Business')\n",
    "data['Q5'] = data['Q5'].replace('Information technology, networking, or system administration', 'Information technology')\n",
    "data['Q5'] = data['Q5'].replace('Medical or life sciences (biology, chemistry, medicine, etc.)', 'Medical/Life Science')\n",
    "data['Q5'] = data['Q5'].replace('Social sciences (anthropology, psychology, sociology, etc.)', 'Social Science')\n",
    "data['Q5'] = data['Q5'].replace('Humanities (history, literature, philosophy, etc.)', 'Humanities')\n",
    "data['Q5'] = data['Q5'].replace('Mathematics or statistics', 'Math')\n",
    "data['Q5'] = data['Q5'].replace('Computer science (software engineering, etc.)', 'Comp. Sci & Soft. Eng.')\n",
    "data['Q5'] = data['Q5'].replace('Engineering (non-computer focused)', 'Engineering (Non. Soft. Eng.)')\n",
    "# Grouped together non-STEM with others\n",
    "data['Q5'] = data['Q5'].replace('I never declared a major', 'Other')\n",
    "data['Q5'] = data['Q5'].replace('Fine arts or performing arts', 'Other')\n",
    "data['Q5'] = data['Q5'].replace('Humanities', 'Other')\n",
    "# sns.catplot(x='Q5', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(25,10)\n",
    "# plt.ylim(0, 200000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: Position Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Position Title\n",
    "# Eliminate position titles less than a threshold\n",
    "title_count = data.Q6.value_counts()\n",
    "value_mask = data.Q6.isin(title_count.index[title_count < 200]) \n",
    "data.loc[value_mask,'Q6'] = \"Other\"\n",
    "# sns.catplot(x='Q6', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(25,10)\n",
    "# plt.ylim(0, 300000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Position Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: Industry\n",
    "industry_count = data.Q7.value_counts()\n",
    "value_mask = data.Q7.isin(industry_count.index[industry_count < 200]) \n",
    "data.loc[value_mask,'Q7'] = \"Other\"\n",
    "# sns.catplot(x='Q7', y='Salary_label', data=data, kind=\"box\").fig.set_size_inches(40,10)\n",
    "# plt.ylim(0, 200000) # limit the y axis to 250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Years of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: Years of Experience\n",
    "# There's 76 missing values - Should just remove it\n",
    "how_many_nan(data['Q8'])\n",
    "# Recategorize YOE\n",
    "data['Q8'] = data['Q8'].replace('0-1', '0-3') # 0-3 years\n",
    "data['Q8'] = data['Q8'].replace('1-2', '0-3')\n",
    "data['Q8'] = data['Q8'].replace('2-3', '0-3')\n",
    "data['Q8'] = data['Q8'].replace('3-4', '3-5') # 3-5 years\n",
    "data['Q8'] = data['Q8'].replace('4-5', '3-5')\n",
    "data['Q8'] = data['Q8'].replace('20-25', '20-30') # 20-30 years\n",
    "data['Q8'] = data['Q8'].replace('25-30', '20-30')\n",
    "# sns.catplot(x='Q8', y='Salary_label', data=data, order=['0-3','3-5','5-10','10-15','15-20','20-30','30 +'], kind=\"box\").fig.set_size_inches(10,5)\n",
    "# plt.ylim(0, 300000) # limit the y axis to 300000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3763"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up Q40\n",
    "Q40_words = ['Independent', 'projects', 'are', 'important', 'than', 'academic', 'achievements']\n",
    "remove_words('Q40', Q40_words)\n",
    "# 3763 missing values\n",
    "how_many_nan(data['Q40'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combine_col:\n",
    "    # Function to concatenate multiple columns of num in to one single column (by addition)\n",
    "    def sum_int(col_name, start, end):\n",
    "        one = data[col_name+'_Part_'+str(start)]\n",
    "        two = data[col_name+'_Part_'+str(start+1)]\n",
    "        col_combined = one+two\n",
    "        # iterate from start to end\n",
    "        for i in range(start+2, end+1):\n",
    "            next_col = data[col_name+'_Part_'+str(i)]\n",
    "            col_combined = col_combined+next_col\n",
    "        # if the sum of specified columns equal to zero, this row was originally a NaN\n",
    "        col_combined = col_combined.replace(0, np.nan)\n",
    "        return col_combined\n",
    "# Class for filling in information\n",
    "class fill_info:\n",
    "    def nan_text(col_name,start, end):\n",
    "        for i in range (start, end+1): #nan2zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        # Before converting all texts to 1, save a list of the categories\n",
    "        features_list = list()\n",
    "        for i in range (start, end+1): # save features to a list\n",
    "            spot = data[col_name+'_Part_'+str(i)].ne(0).idxmax()\n",
    "            feature = data[col_name+'_Part_'+str(i)].iloc[spot-1]\n",
    "            features_list.append(feature)\n",
    "        for i in range (start, end+1): #text2one\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(bool).astype(int)\n",
    "        return features_list\n",
    "    def col2num(col_name, start, end):\n",
    "        for i in range (start, end+1): #fill nan with zero\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].fillna(0)\n",
    "        for i in range (start, end+1): # convert everything to type float\n",
    "            data[col_name+'_Part_'+str(i)] = data[col_name+'_Part_'+str(i)].astype(float)\n",
    "# encode columns with num\n",
    "def encode_col(col_name, start, end):\n",
    "    features = fill_info.nan_text(col_name, start, end)\n",
    "    combined = combine_col.sum_int(col_name, start, end)\n",
    "    return features, combined\n",
    "# creates dummy columns and drops the original column\n",
    "def dummy(col_name):\n",
    "    global data\n",
    "    dummy = pd.get_dummies(data[col_name], prefix=col_name)\n",
    "    data.drop([col_name], axis=1) # need to drop the original columns\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode columns that require dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_dummies = dummy('Q1')\n",
    "Q2_dummies = dummy('Q2')\n",
    "Q3_dummies = dummy('Q3')\n",
    "Q4_dummies = dummy('Q4')\n",
    "Q5_dummies = dummy('Q5')\n",
    "Q6_dummies = dummy('Q6')\n",
    "Q7_dummies = dummy('Q7')\n",
    "Q8_dummies = dummy('Q8')\n",
    "Q10_dummies = dummy('Q10')\n",
    "Q12_dummies = dummy('Q12_MULTIPLE_CHOICE')\n",
    "Q17_dummies = dummy('Q17')\n",
    "Q18_dummies = dummy('Q18')\n",
    "Q20_dummies = dummy('Q20')\n",
    "Q22_dummies = dummy('Q22')\n",
    "Q23_dummies = dummy('Q23')\n",
    "Q24_dummies = dummy('Q24')\n",
    "Q25_dummies = dummy('Q25')\n",
    "Q26_dummies = dummy('Q26')\n",
    "Q32_dummies = dummy('Q32')\n",
    "Q37_dummies = dummy('Q37')\n",
    "Q39P1_dummies = dummy('Q39_Part_1')\n",
    "Q39P2_dummies = dummy('Q39_Part_2')\n",
    "Q40_dummies = dummy('Q40')\n",
    "Q41P1_dummies = dummy('Q41_Part_1')\n",
    "Q41P2_dummies = dummy('Q41_Part_2')\n",
    "Q41P3_dummies = dummy('Q41_Part_3')\n",
    "Q43_dummies = dummy('Q43')\n",
    "Q46_dummies = dummy('Q46')\n",
    "Q48_dummies = dummy('Q48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                               int64\n",
       "Time from Start to Finish (seconds)     object\n",
       "Q1                                      object\n",
       "Q1_OTHER_TEXT                           object\n",
       "Q2                                      object\n",
       "Q3                                      object\n",
       "Q4                                      object\n",
       "Q5                                      object\n",
       "Q6                                      object\n",
       "Q6_OTHER_TEXT                           object\n",
       "Q7                                      object\n",
       "Q7_OTHER_TEXT                           object\n",
       "Q8                                      object\n",
       "Q9                                      object\n",
       "Q10                                     object\n",
       "Q11_Part_1                              object\n",
       "Q11_Part_2                              object\n",
       "Q11_Part_3                              object\n",
       "Q11_Part_4                              object\n",
       "Q11_Part_5                              object\n",
       "Q11_Part_6                              object\n",
       "Q11_Part_7                              object\n",
       "Q11_OTHER_TEXT                          object\n",
       "Q12_MULTIPLE_CHOICE                     object\n",
       "Q12_Part_1_TEXT                         object\n",
       "Q12_Part_2_TEXT                         object\n",
       "Q12_Part_3_TEXT                         object\n",
       "Q12_Part_4_TEXT                         object\n",
       "Q12_Part_5_TEXT                         object\n",
       "Q12_OTHER_TEXT                          object\n",
       "                                        ...   \n",
       "Q47_Part_12                             object\n",
       "Q47_Part_13                             object\n",
       "Q47_Part_14                             object\n",
       "Q47_Part_15                             object\n",
       "Q47_Part_16                             object\n",
       "Q48                                     object\n",
       "Q49_Part_1                              object\n",
       "Q49_Part_2                              object\n",
       "Q49_Part_3                              object\n",
       "Q49_Part_4                              object\n",
       "Q49_Part_5                              object\n",
       "Q49_Part_6                              object\n",
       "Q49_Part_7                              object\n",
       "Q49_Part_8                              object\n",
       "Q49_Part_9                              object\n",
       "Q49_Part_10                             object\n",
       "Q49_Part_11                             object\n",
       "Q49_Part_12                             object\n",
       "Q49_OTHER_TEXT                          object\n",
       "Q50_Part_1                              object\n",
       "Q50_Part_2                              object\n",
       "Q50_Part_3                              object\n",
       "Q50_Part_4                              object\n",
       "Q50_Part_5                              object\n",
       "Q50_Part_6                              object\n",
       "Q50_Part_7                              object\n",
       "Q50_Part_8                              object\n",
       "Q50_OTHER_TEXT                          object\n",
       "index                                  float64\n",
       "Salary_label                             int64\n",
       "Length: 398, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes #suppose to drop each of the original dummy columns but it is currently not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these two Q's are percentage based\n",
    "fill_info.col2num('Q34', 1, 6)# Q34\n",
    "Q34_combined = combine_col.sum_int('Q34',1,6)\n",
    "fill_info.col2num('Q35', 1, 6)# Q35\n",
    "Q35_combined = combine_col.sum_int('Q35',1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11_features, Q11_combined = encode_col('Q11', 1, 7)\n",
    "Q13_features, Q13_combined = encode_col('Q13', 1, 15)\n",
    "Q14_features, Q14_combined = encode_col('Q14', 1, 11)\n",
    "Q15_features, Q15_combined = encode_col('Q15', 1, 7)\n",
    "Q16_features, Q16_combined = encode_col('Q16', 1, 18)\n",
    "Q19_features, Q19_combined = encode_col('Q19', 1, 19)\n",
    "Q21_features, Q21_combined = encode_col('Q21', 1, 13)\n",
    "Q27_features, Q27_combined = encode_col('Q27', 1, 20)\n",
    "Q28_features, Q28_combined = encode_col('Q28', 1, 43)\n",
    "Q29_features, Q29_combined = encode_col('Q29', 1, 28)\n",
    "Q30_features, Q30_combined = encode_col('Q30', 1, 25)\n",
    "Q31_features, Q31_combined = encode_col('Q31', 1, 12)\n",
    "Q33_features, Q33_combined = encode_col('Q33', 1, 11)\n",
    "Q36_features, Q36_combined = encode_col('Q36', 1, 13)\n",
    "Q38_features, Q38_combined = encode_col('Q38', 1, 22)\n",
    "Q42_features, Q42_combined = encode_col('Q42', 1, 5)\n",
    "Q44_features, Q44_combined = encode_col('Q44', 1, 6)\n",
    "Q45_features, Q45_combined = encode_col('Q45', 1, 6)\n",
    "Q47_features, Q47_combined = encode_col('Q47', 1, 16)\n",
    "Q49_features, Q49_combined = encode_col('Q49', 1, 12)\n",
    "Q50_features, Q50_combined = encode_col('Q50', 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently new_data and data isnt working, the idea is to drop the original column aftter the dummy function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate dummy and categorical features to find NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fef60e28748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new data frame with all the combined columns\n",
    "cat_encoded = pd.concat([Q11_combined, Q13_combined, Q14_combined, Q15_combined, Q16_combined, Q19_combined, Q21_combined, Q27_combined, Q28_combined, Q29_combined, Q30_combined, Q31_combined, Q33_combined, Q34_combined, Q35_combined, Q36_combined, Q38_combined, Q42_combined, Q44_combined, Q45_combined, Q47_combined, Q49_combined, Q50_combined],axis=1)\n",
    "cat_encoded.columns = ['Q11','Q13','Q14','Q15','Q16','Q19','Q21','Q27','Q28','Q29','Q30','Q31','Q33','Q34','Q35','Q36','Q38','Q42','Q44','Q45','Q47','Q49','Q50']\n",
    "# new data frame with all the ones that were made dummy\n",
    "dummy_encoded = pd.concat([data['Q1'],data['Q2'],data['Q3'],data['Q4'],data['Q5'],data['Q6'],data['Q7'],data['Q8'],data['Q10'],data['Q12_MULTIPLE_CHOICE'],data['Q17'],data['Q18'],data['Q20'],data['Q22'],data['Q23'],data['Q24'],data['Q25'],data['Q26'],data['Q32'],data['Q37'],data['Q39_Part_1'],data['Q39_Part_2'],data['Q40'],data['Q41_Part_1'],data['Q41_Part_2'],data['Q41_Part_3'],data['Q43'],data['Q46'],data['Q48']], axis=1)\n",
    "# Check missing values from the whole data set\n",
    "encoded_all = pd.concat([dummy_encoded, cat_encoded], axis=1)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.heatmap(encoded_all.isnull(), cmap='coolwarm', yticklabels=False, cbar=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to deal with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-429a3bfffa94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "new_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5bb3cd21b011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdummy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ1_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ2_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ3_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ4_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ5_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ6_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ7_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ8_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ10_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ12_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ17_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ18_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ20_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ22_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ23_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ24_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ25_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ26_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ32_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ37_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ39P1_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ39P2_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ40_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ41P1_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ41P2_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ41P3_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ43_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ46_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ48_dummies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# drop any column with \"TEXT\" in title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'TEXT'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# drop other unecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time from Start to Finish (seconds)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Salary_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "# concatenate all dummy data\n",
    "dummy_data = pd.concat([Q1_dummies, Q2_dummies, Q3_dummies, Q4_dummies, Q5_dummies, Q6_dummies, Q7_dummies, Q8_dummies, Q10_dummies, Q12_dummies, Q17_dummies, Q18_dummies, Q20_dummies, Q22_dummies, Q23_dummies, Q24_dummies, Q25_dummies, Q26_dummies, Q32_dummies, Q37_dummies, Q39P1_dummies, Q39P2_dummies, Q40_dummies, Q41P1_dummies, Q41P2_dummies, Q41P3_dummies, Q43_dummies, Q46_dummies, Q48_dummies], axis=1)\n",
    "# drop any column with \"TEXT\" in title\n",
    "new_data.drop([col for col in data.columns if 'TEXT' in col],axis=1,inplace=True)\n",
    "# drop other unecessary columns\n",
    "new_data.drop(['Unnamed: 0', 'Time from Start to Finish (seconds)', 'index', 'Salary_label'], axis=1, inplace=True)\n",
    "# form cleaned data\n",
    "cleaned_data = pd.concat([dummy_data, new_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Female               uint8\n",
       "Q1_Male                 uint8\n",
       "Q1_Other                uint8\n",
       "Q2_18-21                uint8\n",
       "Q2_22-24                uint8\n",
       "Q2_25-29                uint8\n",
       "Q2_30-34                uint8\n",
       "Q2_35-39                uint8\n",
       "Q2_40-44                uint8\n",
       "Q2_45-49                uint8\n",
       "Q2_50-54                uint8\n",
       "Q2_55-59                uint8\n",
       "Q2_60-69                uint8\n",
       "Q2_70+                  uint8\n",
       "Q3_Australia            uint8\n",
       "Q3_Brazil               uint8\n",
       "Q3_Canada               uint8\n",
       "Q3_China                uint8\n",
       "Q3_France               uint8\n",
       "Q3_Germany              uint8\n",
       "Q3_India                uint8\n",
       "Q3_Italy                uint8\n",
       "Q3_Japan                uint8\n",
       "Q3_Other                uint8\n",
       "Q3_Poland               uint8\n",
       "Q3_Russia               uint8\n",
       "Q3_Spain                uint8\n",
       "Q3_UKGBNI               uint8\n",
       "Q3_USA                  uint8\n",
       "Q4_Doctoral degree      uint8\n",
       "                       ...   \n",
       "Q47_Part_12             int64\n",
       "Q47_Part_13             int64\n",
       "Q47_Part_14             int64\n",
       "Q47_Part_15             int64\n",
       "Q47_Part_16             int64\n",
       "Q48                    object\n",
       "Q49_Part_1              int64\n",
       "Q49_Part_2              int64\n",
       "Q49_Part_3              int64\n",
       "Q49_Part_4              int64\n",
       "Q49_Part_5              int64\n",
       "Q49_Part_6              int64\n",
       "Q49_Part_7              int64\n",
       "Q49_Part_8              int64\n",
       "Q49_Part_9              int64\n",
       "Q49_Part_10             int64\n",
       "Q49_Part_11             int64\n",
       "Q49_Part_12             int64\n",
       "Q49_OTHER_TEXT         object\n",
       "Q50_Part_1              int64\n",
       "Q50_Part_2              int64\n",
       "Q50_Part_3              int64\n",
       "Q50_Part_4              int64\n",
       "Q50_Part_5              int64\n",
       "Q50_Part_6              int64\n",
       "Q50_Part_7              int64\n",
       "Q50_Part_8              int64\n",
       "Q50_OTHER_TEXT         object\n",
       "index                 float64\n",
       "Salary_label            int64\n",
       "Length: 662, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data.drop(['Q9'],axis=1)\n",
    "y = cleaned_data['Q9']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = linear_model.Lasso(alpha=0.1)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/aaron/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None, solver='warn',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "sel_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 595\n",
      "selected features: 591\n",
      "features with coefficients shrank to zero: 4743\n"
     ]
    }
   ],
   "source": [
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 595 but corresponding boolean dimension is 10710",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-7378b7a7b11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremoved_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mremoved_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3969\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpromote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 595 but corresponding boolean dimension is 10710"
     ]
    }
   ],
   "source": [
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data.drop(['Q9'],axis=1)\n",
    "y = cleaned_data['Q9']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = LogisticRegression()    \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy: 0.784%\n",
      "Fold 2: Accuracy: 0.73%\n",
      "Fold 3: Accuracy: 0.711%\n",
      "Fold 4: Accuracy: 0.747%\n",
      "Fold 5: Accuracy: 0.75%\n",
      "Fold 6: Accuracy: 0.746%\n",
      "Fold 7: Accuracy: 0.771%\n",
      "Fold 8: Accuracy: 0.767%\n",
      "Fold 9: Accuracy: 0.737%\n",
      "Fold 10: Accuracy: 0.772%\n",
      "Average Score: 75.161%(2.114%)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "kfold = KFold(n_splits=10)\n",
    "kfold.get_n_splits(X)\n",
    "\n",
    "accuracy = np.zeros(10)\n",
    "np_idx = 0\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.values[train_idx], X.values[test_idx]\n",
    "    y_train, y_test = y.values[train_idx], y.values[test_idx]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    TN = confusion_matrix(y_test, predictions)[0][0]\n",
    "    FP = confusion_matrix(y_test, predictions)[0][1]\n",
    "    FN = confusion_matrix(y_test, predictions)[1][0]\n",
    "    TP = confusion_matrix(y_test, predictions)[1][1]\n",
    "    total = TN + FP + FN + TP\n",
    "    ACC = (TP + TN) / float(total)\n",
    "    \n",
    "    accuracy[np_idx] = ACC*100\n",
    "    np_idx += 1\n",
    "    \n",
    "    print (\"Fold {}: Accuracy: {}%\".format(np_idx, round(ACC,3)))   \n",
    "\n",
    "print (\"Average Score: {}%({}%)\".format(round(np.mean(accuracy),3),round(np.std(accuracy),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
